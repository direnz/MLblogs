---
title: "LDAandQDA"
output: pdf_document
date: "2024-02-15"
---

```{r}
############# libraries used ############
# for methods
library(MASS)  #help(lda)
library(pROC)
# for assumption-checking (none)
# for visuals
library(dplyr)
library(ggformula)

library(mvnormalTest)  # of multivariate normality; or library(MVN) or (mvnTest)
library(MVTests)  # of constant covariance; or library(biotools) or (biotools) or (heplots)

# added lines to specify version of iris data set
library(MVTests)
iris <- MVTests::iris  # added to require the version of the iris data set with capitalized Species names
levels(iris$Species)
```

```{r}
############# Review data #############

data(iris)
n = dim(iris)[1]; n
names(iris)
levels(iris$Species)
K=length(levels(iris$Species)); K
```

```{r}
# try different options: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width
boxplot(Petal.Length ~ Species, data = iris)
gf_boxplot(Petal.Length ~ Species, data = iris,fill=c("skyblue","navy","purple"))
#both Petal.Length and Petal.Width look like good candidates for predictors
```

```{r}
############# ROC of LDA predictions for two-level response ############# 
# just using the predictor values since decide off linear function of predictor
iris$Virginica = as.numeric(iris$Species == "Virginica")
lda.roc1 = roc(response=iris$Virginica, 
               predictor=iris$Petal.Length)
plot.roc(lda.roc1)

# using posterior probabilities
ldafitVirg = lda(Virginica~Petal.Length, data=iris)
# posterior probability of Virginica species
ldaprob = predict(ldafitVirg,data=iris)$posterior[,2]
# posterior probability way of ROC curve for LDA
lda.roc2 = roc(response=iris$Virginica, 
               predictor=ldaprob)
plot.roc(lda.roc2)  # exact same curve as above
```

```{r}
############# apply LDA with three classes in Species #############
ldafit = lda(Species~Petal.Length, data=iris)
ldafit

# look at error, re-predicting data used to fit the model
y = iris$Species
predclass = predict(ldafit,data=iris)$class

table(y,predclass)
fitError = sum(y != predclass)/n; fitError
```

```{r}
############# Honest prediction via cross-validation #############
CVpredclass = rep("NA",n)

# define cvgroups
nfolds = 10
groups = c(rep(1:nfolds,length=n))
set.seed(4)
cvgroups = sample(groups,n)

# loop through cvgroups, to compute honest predicted values for CV measure
for (ii in 1: nfolds) {    # ii is an easier string to search for index
  groupii = (cvgroups == ii)
  trainset = iris[!groupii,]  # all data EXCEPT for group ii
  testset = iris[groupii, ]   # data in group ii

  ldafitii = lda(Species~Petal.Length, data=trainset)

#  predicted = predict(ldafitii, newdata=testset)$class   # predict for test set
  predicted = as.character(predict(ldafitii, newdata=testset)$class)   # predict for test set
  CVpredclass[groupii] = predicted              # store in ordered locations
}

# compute CV measure as misclassification rate
table(y,CVpredclass)
CVError = sum(CVpredclass!=y)/n; CVError
```

```{r}
############# Check Assumptions #############
xvar = iris$Petal.Length
xSetosa = xvar[iris$Species == "Setosa"]
xVersicolor = xvar[iris$Species == "Versicolor"]
xVirginica = xvar[iris$Species == "Virginica"]

shapiro.test(xSetosa); qqnorm(xSetosa)
shapiro.test(xVersicolor); qqnorm(xVersicolor)
shapiro.test(xVirginica); qqnorm(xVirginica)
#normality of the Petal.Length is reasonable

bartlett.test(xvar,iris$Species)
iris %>%
  group_by(Species) %>% 
  summarize(GroupSD = sd(Petal.Length))



```

```{r}
#statistics by class of Species
pi.hat1 = length(xSetosa)/n
pi.hat2 = length(xVersicolor)/n
pi.hat3 = length(xVirginica)/n
mu.hat1 = mean(xSetosa)
mu.hat2 = mean(xVersicolor)
mu.hat3 = mean(xVirginica)
sigma2 = 1/(n-K)*(sum((xSetosa-mu.hat1)^2)+sum((xVersicolor-mu.hat2)^2)+sum((xVirginica-mu.hat3)^2))

#linear decision boundaries
slope1 = (mu.hat1/sigma2); int1 = (-(1/2)*mu.hat1^2/sigma2 + log(pi.hat1))
slope2 = (mu.hat2/sigma2); int2 = (-(1/2)*mu.hat2^2/sigma2 + log(pi.hat2))
slope3 = (mu.hat3/sigma2); int3 = (-(1/2)*mu.hat3^2/sigma2 + log(pi.hat3))
hist(xSetosa,col="skyblue", main = "Petal Length, split by Species",
     xlim=c(0,max(iris$Petal.Length)),ylim=c(0,90),
     ylab="Linear.k",xlab="Petal Length")
hist(xVersicolor,col=rgb(0,0,.3,0.6),add=T,breaks=20)
hist(xVirginica,col=rgb(0.4,0,0.6,0.5),add=T,breaks=20)

curve(slope1*x+int1,col="skyblue",lwd=2,add=T)
abline(int2,slope2,col="navy",lwd=2)
abline(int3,slope3,col="purple",lwd=2)
legend("topleft",c("setosa","versicolor","virginica"),col=c("skyblue","navy","purple"),lwd=2)

bound12 = (int1-int2)/(slope2-slope1); bound12; abline(v=bound12,lty=2)
bound23 = (int2-int3)/(slope3-slope2); bound23; abline(v=bound23,lty=2)

#looking at the original goal functions
p1num = function(x) 1/(sqrt(2*pi))/sqrt(sigma2)*exp(-.5*(x-mu.hat1)^2/sigma2)*pi.hat1
p2num = function(x) 1/(sqrt(2*pi))/sqrt(sigma2)*exp(-.5*(x-mu.hat2)^2/sigma2)*pi.hat1
p3num = function(x) 1/(sqrt(2*pi))/sqrt(sigma2)*exp(-.5*(x-mu.hat3)^2/sigma2)*pi.hat1
hist(xSetosa,col="skyblue", main = "Petal Length, split by Species",
     xlim=c(0,max(iris$Petal.Length)),ylim=c(0,2.5),
     ylab="p_k(x)",xlab="Petal Length",prob=T,breaks=5)
hist(xVersicolor,col=rgb(0,0,.3,0.6),add=T,breaks=10,prob=T)
hist(xVirginica,col=rgb(0.4,0,0.6,0.5),add=T,breaks=10,prob=T)
curve(p1num(x)/(p1num(x)+p2num(x)+p3num(x)),add=T,col="skyblue3")
curve(p2num(x)/(p1num(x)+p2num(x)+p3num(x)),add=T,col="navy")
curve(p3num(x)/(p1num(x)+p2num(x)+p3num(x)),add=T,col="purple")
abline(v=bound12,lty=2); abline(v=bound23,lty=2)
```

```{r}
#looking at the original goal functions
p1num = function(x) 1/(sqrt(2*pi))/sqrt(sigma2)*exp(-.5*(x-mu.hat1)^2/sigma2)*pi.hat1
p2num = function(x) 1/(sqrt(2*pi))/sqrt(sigma2)*exp(-.5*(x-mu.hat2)^2/sigma2)*pi.hat1
p3num = function(x) 1/(sqrt(2*pi))/sqrt(sigma2)*exp(-.5*(x-mu.hat3)^2/sigma2)*pi.hat1
hist(xSetosa,col="skyblue", main = "Petal Length, split by Species",
     xlim=c(0,max(iris$Petal.Length)),ylim=c(0,2.5),
     ylab="p_k(x)",xlab="Petal Length",prob=T,breaks=5)
hist(xVersicolor,col=rgb(0,0,.3,0.6),add=T,breaks=10,prob=T)
hist(xVirginica,col=rgb(0.4,0,0.6,0.5),add=T,breaks=10,prob=T)
curve(p1num(x)/(p1num(x)+p2num(x)+p3num(x)),add=T,col="skyblue3")
curve(p2num(x)/(p1num(x)+p2num(x)+p3num(x)),add=T,col="navy")
curve(p3num(x)/(p1num(x)+p2num(x)+p3num(x)),add=T,col="purple")
abline(v=bound12,lty=2); abline(v=bound23,lty=2)
```
Start of QDA
```{r}
############# set-up groups for cross-validation #############
nfolds = 10
groups = c(rep(1:nfolds,length=n))
set.seed(4)
cvgroups = sample(groups,n)

############# apply LDA, using one predictor to classify Species (Model L1) #############
#methodapplied = "LDA"
#modelapplied = (Species~Petal.Length)
############# apply QDA, using one predictor to classify Species (Model Q1) #############
#methodapplied = "QDA"
#modelapplied = (Species~Petal.Length)
############# apply LDA, using all 4 predictors to classify Species (Model L4) #############
#methodapplied = "LDA"
#modelapplied = (Species~.)
############# apply QDA, using all 4 predictors to classify Species (Model Q4) #############
methodapplied = "QDA"
modelapplied = (Species~.)

# look at error, re-predicting data used to fit the model
y = iris$Species
if (methodapplied == "LDA") {
  modelfit = lda(modelapplied, data=iris) } else if (methodapplied == "QDA") {
  modelfit = qda(modelapplied, data=iris)
}
predclass = predict(modelfit,data=iris)$class
table(y,predclass)
fitError = sum(y != predclass)/n; fitError

# Honest prediction via cross-validation
CVpredclass = rep("NA",n)
# loop through cvgroups, to compute honest predicted values for CV measure
for (ii in 1: nfolds) {    # ii is an easier string to search for index
  groupii = (cvgroups == ii)
  trainset = iris[!groupii,]  # all data EXCEPT for group ii
  testset = iris[groupii, ]   # data in group ii
  
  if (methodapplied == "LDA") {
    modelfitii = lda(modelapplied, data=trainset) } else if (methodapplied == "QDA") {
    modelfitii = qda(modelapplied, data=trainset)
  }
  
  predicted = as.character(predict(modelfitii, newdata=testset)$class)   # predict for test set
  CVpredclass[groupii] = predicted              # store in ordered locations
}

# compute CV measure as misclassification rate
table(y,CVpredclass)
CVError = sum(CVpredclass!=y)/n; CVError

#CVErrorL1 = CVError
#CVErrorQ1 = CVError
#CVErrorL4 = CVError
#CVErrorQ4 = CVError
```

```{r}
############# Model selection ############# 
CVErrorL1   #lda with 1 predictor
CVErrorQ1   #qda with 1 predictor
CVErrorL4   #lda with 4 predictors
CVErrorQ4   #qda with 4 predictors

#equal covariance matrices are definitely NOT reasonable, 
#  so we prefer models Q1 and Q4 (QDA) to the LDA models 
#  and model Q4 has a slightly lower CV than does model Q1, 
#  so we select model Q4
```

```{r}
############# Checking Assumptions ############# 
#assumptions for models using all four predictors

# full Xmatrix
xvar = iris %>% 
  select(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)
# Xmatrix within each class
xSetosa = iris %>% 
  filter(Species == "Setosa") %>% 
  select(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)
xVersicolor = iris %>% 
  filter(Species == "Versicolor") %>% 
  select(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)
xVirginica = iris %>% 
  filter(Species == "Virginica") %>% 
  select(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)

# check for multivariate normality
mhz(xSetosa)$mv.test
mhz(xVersicolor)$mv.test
mhz(xVirginica)$mv.test
#multivariate normality of the predictors is (close to) reasonable

# check for equal covariance
BoxM(xvar,iris$Species)
# equal covariance matrices are definitely NOT reasonable, 
#  so QDA is the better option
```

```{r}
############# ROC of LDA and QDA predictions for two-level response ############# 
# just using the predictor values since decide off linear function of predictor
iris$Virginica = as.numeric(iris$Species == "Virginica")
# fit models
ldafitVirg = lda(Virginica~.-Species, data=iris)
qdafitVirg = qda(Virginica~.-Species, data=iris)
# posterior probability of Virginica species
ldaprob = predict(ldafitVirg,data=iris)$posterior[,2]
qdaprob = predict(qdafitVirg,data=iris)$posterior[,2]
# ROC curve for LDA fit of Virginica on four predictors
lda.roc = roc(response=iris$Virginica, 
              predictor=ldaprob)
plot.roc(lda.roc)  
# ROC curve for QDA fit of Virginica on four predictors
qda.roc = roc(response=iris$Virginica, 
              predictor=qdaprob)
plot.roc(qda.roc)  
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```